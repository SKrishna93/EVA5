# -*- coding: utf-8 -*-
"""NewResnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pYX-0FIXwn06esNVvurawXHORMS9B4sr
"""

class Net(nn.Module):
  def __init__(self):
    super(Net, self).__init__()

    self.PrepLayer = nn.Sequential(
        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, bias=False),
        nn.BatchNorm2d(64),
        nn.ReLU()
    )

#Layer 1
    self.x1 = nn.Sequential(
        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, bias=False),
        nn.MaxPool2d(2, 2),
        nn.BatchNorm2d(128),
        nn.ReLU()
    )

    self.R1 = nn.Sequential(
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=1, bias=False), 
            nn.BatchNorm2d(128),
            nn.ReLU(),

            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=1, bias=False), 
            nn.BatchNorm2d(128),
            nn.ReLU()
            )

#Layer2
    self.Layer2 = nn.Sequential(
        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, bias=False),
        nn.MaxPool2d(2, 2),
        nn.BatchNorm2d(256),
        nn.ReLU()
    )


#Layer 3
    self.x2 = nn.Sequential(
        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, bias=False),
        nn.MaxPool2d(2, 2),
        nn.BatchNorm2d(512),
        nn.ReLU()
    )

    self.R2 = nn.Sequential(
        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3, 3), padding=1, bias=False), 
        nn.BatchNorm2d(512),
        nn.ReLU(),
        
        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3, 3), padding=1, bias=False),
        nn.BatchNorm2d(512),
        nn.ReLU()
    )

#MaxPool Layer
    self.MaxPool = nn.MaxPool2d(4,4)

#Fully Connected
    self.FC= nn.Linear(in_features = 512, out_features = 10, bias=False)
 

  def forward(self, x):
    PrepLayer = self.PrepLayer(x)
    x1 = self.x1(PrepLayer)
    R1 = self.R1(x1)
    Layer1=R1+x1
    Layer2=self.Layer2(Layer1)
    x2=self.x2(Layer2)
    R2=self.R2(x2)
    Layer3=x2+R2
    Pool=self.MaxPool(Layer3)
    Pool=Pool.view(Pool.size(0),-1)
    fc=self.FC(Pool)

    return F.log_softmax(fc)